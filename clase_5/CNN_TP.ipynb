{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_1a5iymIvC"
      },
      "source": [
        "## 8. EJERCICIO\n",
        "\n",
        "Vamos a armar una pequeña competición en el curso.\n",
        "El objetivo es armar una arquitectura de CNN que identifique el dataset MNIST.\n",
        "Se van a usar capas de convolución, de activación y de pooling a elección. Cada alumno eligirá su modelo y los respectivos hiperparámetros, lo entrenará y presentará los siguientes resultados:\n",
        "\n",
        "*   `test_acc` (del test final)\n",
        "*   `n_parameter`\n",
        "*   `n_layers` (conv + activacion + pooling = 1 capa)\n",
        "*   `n_epochs` de entrenamiento usadas.\n",
        "\n",
        "\n",
        "El modelo se deberá ajustar a los siguientes parámetros:\n",
        "\n",
        "*   train: 80%, validation: 10%, test: 10% (los datos serán dados así todos usan el mismo set para cada grupo. Están en el github el curso).\n",
        "*   capa final de salida será una softmax de 10 elementos.\n",
        "*   loss_function será `CrossEntropyLoss`.\n",
        "\n",
        "El ganador de la competencia será aquel que consiga el mayor `score` empleando la siguietne fórmula:\n",
        "\n",
        "$$ score = \\frac{1}{log_{10}(n\\_parameter)} * \\frac{10}{n\\_epochs}*test\\_acc*n\\_layers$$\n",
        "\n",
        "Deberan presentar su código colab funcionando y el score alcanzado (con los valores de cada variable que compone el score).\n",
        "\n",
        "Es una competencia fairplay y con fines didácticos, esta formula del ```score``` fué inventada.... no usar como referencia para definir qué modelo utilizar.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIQ8hjDpdVi"
      },
      "source": [
        "#### Importar lo necesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uHQUjDs12DLW"
      },
      "outputs": [],
      "source": [
        "%load_ext lab_black\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm  # <- para graficar la barra de avance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJy8fjPn4wi"
      },
      "source": [
        "#### configuramos el `device` acorde al device disponible\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lOV9xybtn4I3"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQ-MLk6Do8e"
      },
      "source": [
        "1. Cargar base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "basepath = \"/tf/notebooks/CEIA-deep_learning/clase_5/data\"\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def custom_dataloader(data_file, label_file, batch_size=512):\n",
        "    data = np.load(os.path.join(basepath, data_file), allow_pickle=True)\n",
        "    data = np.expand_dims(data, axis=1)\n",
        "    labels = np.load(os.path.join(basepath, label_file), allow_pickle=True)\n",
        "    dataset = CustomDataset(data, labels)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "dataloader = {\n",
        "    \"train\": custom_dataloader(\"train.pkl\", \"train_label.pkl\"),\n",
        "    \"val\": custom_dataloader(\"val.pkl\", \"val_label.pkl\"),\n",
        "    \"test\": custom_dataloader(\"test.pkl\", \"test_label.pkl\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oikthAE4Dteb"
      },
      "source": [
        "2. Ver que la base de datos esté OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyq2UFIl-Qjy",
        "outputId": "ed7a0a94-d5e7-4ae4-b111-118f9805fae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "print(type(dataloader))\n",
        "print(type(dataloader[\"train\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "p2fs6Qdivs1H",
        "outputId": "6cfc7823-33d2-4c0d-b0e5-907d4727d227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([512, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([512])\n",
            "tamaño de 1 imagen:  torch.Size([1, 28, 28])\n",
            "tamaño 1 imagen DESPUES de squeeze:  torch.Size([28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ]
        }
      ],
      "source": [
        "# Display image and label from dataloader (dataloader -> una herramienta para hacer batches de datasets)\n",
        "train_features, train_labels = next(iter(dataloader[\"train\"]))\n",
        "\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "img = train_features[0]\n",
        "print(\"tamaño de 1 imagen: \", img.shape)\n",
        "# le QUITO 1 dimension (la del tamaño del batch) para poder graficar\n",
        "img = train_features[0].squeeze()\n",
        "print(\"tamaño 1 imagen DESPUES de squeeze: \", img.shape)\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0TN4erDxRd"
      },
      "source": [
        "3. Construyo mi CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1, out_channels=32, kernel_size=7, padding=\"same\", stride=1\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear = nn.Linear(in_features=32 * 14 * 14, out_features=10)\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv1(input)\n",
        "        out = self.relu(out)\n",
        "        out = self.pool1(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def fit(self, dataloader, epochs=10, lr=1e-3):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            train_loss, train_acc = [], []\n",
        "            bar = tqdm(dataloader[\"train\"])\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device).float(), y.to(device).long()\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = model(X)\n",
        "                loss = criterion(y_pred, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss.append(loss.item())\n",
        "                ####\n",
        "                acc = (y == torch.argmax(y_pred, axis=1)).sum().item() / len(y)\n",
        "                train_acc.append(acc)\n",
        "                bar.set_description(\n",
        "                    f\"Epoch {epoch+1}/{epochs}:\\tloss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\"\n",
        "                )\n",
        "\n",
        "            self.eval()\n",
        "            val_loss, val_acc = [], []\n",
        "            bar = tqdm(dataloader[\"test\"])\n",
        "            with torch.no_grad():\n",
        "                for batch in bar:\n",
        "                    X, y = batch\n",
        "                    X, y = X.to(device).float(), y.to(device).long()\n",
        "                    y_pred = model(X)\n",
        "                    loss = criterion(y_pred, y)\n",
        "                    val_loss.append(loss.item())\n",
        "                    acc = (y == torch.argmax(y_pred, axis=1)).sum().item() / len(y)\n",
        "                    val_acc.append(acc)\n",
        "                    bar.set_description(\n",
        "                        f\"\\t\\tval_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]           1,600\n",
            "              ReLU-2           [-1, 32, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
            "           Flatten-4                 [-1, 6272]               0\n",
            "            Linear-5                   [-1, 10]          62,730\n",
            "================================================================\n",
            "Total params: 64,330\n",
            "Trainable params: 64,330\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.48\n",
            "Params size (MB): 0.25\n",
            "Estimated Total Size (MB): 0.73\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:\tloss 7.23879 acc 0.85196: 100% 110/110 [00:00<00:00, 133.61it/s]\n",
            "\tval_loss 0.53987 val_acc 0.95509: 100% 14/14 [00:00<00:00, 228.36it/s]\n",
            "Epoch 2/10:\tloss 0.32943 acc 0.96471: 100% 110/110 [00:00<00:00, 136.79it/s]\n",
            "\tval_loss 0.31751 val_acc 0.96759: 100% 14/14 [00:00<00:00, 227.42it/s]\n",
            "Epoch 3/10:\tloss 0.16151 acc 0.97597: 100% 110/110 [00:00<00:00, 127.90it/s]\n",
            "\tval_loss 0.25017 val_acc 0.97177: 100% 14/14 [00:00<00:00, 184.96it/s]\n",
            "Epoch 4/10:\tloss 0.09796 acc 0.98195: 100% 110/110 [00:00<00:00, 132.34it/s]\n",
            "\tval_loss 0.21055 val_acc 0.97273: 100% 14/14 [00:00<00:00, 228.80it/s]\n",
            "Epoch 5/10:\tloss 0.06355 acc 0.98581: 100% 110/110 [00:00<00:00, 132.18it/s]\n",
            "\tval_loss 0.20224 val_acc 0.97400: 100% 14/14 [00:00<00:00, 222.24it/s]\n",
            "Epoch 6/10:\tloss 0.04505 acc 0.98882: 100% 110/110 [00:00<00:00, 135.55it/s]\n",
            "\tval_loss 0.17704 val_acc 0.97672: 100% 14/14 [00:00<00:00, 220.65it/s]\n",
            "Epoch 7/10:\tloss 0.03059 acc 0.99134: 100% 110/110 [00:00<00:00, 135.51it/s]\n",
            "\tval_loss 0.16823 val_acc 0.97866: 100% 14/14 [00:00<00:00, 226.93it/s]\n",
            "Epoch 8/10:\tloss 0.02284 acc 0.99275: 100% 110/110 [00:00<00:00, 134.63it/s]\n",
            "\tval_loss 0.17330 val_acc 0.97560: 100% 14/14 [00:00<00:00, 231.00it/s]\n",
            "Epoch 9/10:\tloss 0.01544 acc 0.99506: 100% 110/110 [00:00<00:00, 134.42it/s]\n",
            "\tval_loss 0.17474 val_acc 0.97817: 100% 14/14 [00:00<00:00, 213.43it/s]\n",
            "Epoch 10/10:\tloss 0.01081 acc 0.99635: 100% 110/110 [00:00<00:00, 131.72it/s]\n",
            "\tval_loss 0.17404 val_acc 0.97804: 100% 14/14 [00:00<00:00, 209.26it/s]\n"
          ]
        }
      ],
      "source": [
        "model.fit(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aQ5n86Kwk7B"
      },
      "source": [
        "# score final"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_TP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
